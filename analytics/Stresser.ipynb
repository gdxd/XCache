{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "service = \"http://192.170.227.234:80\"\n",
    "# service = \"http://localhost:80\"\n",
    "\n",
    "sites = ['AGLT2', 'MWT2']\n",
    "dataset = 'AUG'\n",
    "\n",
    "GB = 1024 * 1024 * 1024\n",
    "TB = 1024 * GB\n",
    "PB = 1024 * TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: AGLT2\n",
      "2426114 files\n",
      "1079025  unique files\n",
      "3.40435105065868 PB\n",
      "1.4713738955776505 GB avg. file size\n",
      "----------------------------\n",
      "Loading: MWT2\n",
      "7909781 files\n",
      "3092063  unique files\n",
      "9.52159464423143 PB\n",
      "1.262249312044117 GB avg. file size\n",
      "----------------------------\n",
      "---------- merged data -----------\n",
      "10335895 files\t\t 4128678 unique files\n",
      "12.92594569489011 PB\n",
      "1.3113365057370547 GB avg. file size\n"
     ]
    }
   ],
   "source": [
    "all_accesses = []\n",
    "for si, site in enumerate(sites):\n",
    "    print('Loading:', site)\n",
    "    all_accesses.append(pd.read_hdf(site + '_' + dataset + '.h5', key=site, mode='r'))\n",
    "    all_accesses[si]['site'] = 'xc_' + site\n",
    "    # print(all_accesses[si].head())\n",
    "    print(all_accesses[si].filesize.count(), \"files\")\n",
    "    print(all_accesses[si].index.unique().shape[0], \" unique files\")\n",
    "    print(all_accesses[si].filesize.sum() / PB, \"PB\")\n",
    "    print(all_accesses[si].filesize.mean() / GB, \"GB avg. file size\")\n",
    "    print('----------------------------')\n",
    "\n",
    "all_data = pd.concat(all_accesses).sort_values('transfer_start')\n",
    "\n",
    "print('---------- merged data -----------')\n",
    "print(all_data.shape[0], 'files\\t\\t', all_data.index.unique().shape[0], 'unique files' )\n",
    "print(all_data.filesize.sum() / PB, \"PB\")\n",
    "print(all_data.filesize.mean() / GB, \"GB avg. file size\")\n",
    "# print(all_data.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- start requests ----------\n",
      "5000 [1.0, 0.0, 0.0, 0.0] [1.0, 0.0, 0.0, 0.0]\n",
      "10000 [1.0, 0.0, 0.0, 0.0] [1.0, 0.0, 0.0, 0.0]\n",
      "15000 [1.0, 0.0, 0.0, 0.0] [1.0, 0.0, 0.0, 0.0]\n",
      "20000 [1.0, 0.0, 0.0, 0.0] [1.0, 0.0, 0.0, 0.0]\n",
      "25000 [1.0, 0.0, 0.0, 0.0] [1.0, 0.0, 0.0, 0.0]\n",
      "30000 [1.0, 0.0, 0.0, 0.0] [1.0, 0.0, 0.0, 0.0]\n",
      "35000 [1.0, 0.0, 0.0, 0.0] [1.0, 0.0, 0.0, 0.0]\n",
      "40000 [0.948375, 0.0, 0.0, 0.051625] [0.9892622530174727, 0.0, 0.0, 0.010737746982527307]\n",
      "45000 [0.8715111111111111, 0.0, 0.0, 0.1284888888888889] [0.9012021299159659, 0.0, 0.0, 0.0987978700840341]\n",
      "50000 [0.8079, 0.0033, 0.0, 0.1888] [0.8196479825665484, 0.008781623724205764, 0.0, 0.17157039370924582]\n",
      "55000 [0.7616545454545455, 0.005436363636363637, 0.0, 0.2329090909090909] [0.7445848813113738, 0.021478526373855084, 0.0, 0.23393659231477115]\n",
      "60000 [0.7311, 0.007683333333333334, 0.0, 0.26121666666666665] [0.7099474742945413, 0.03255611793668364, 0.0, 0.257496407768775]\n",
      "65000 [0.7043538461538461, 0.007184615384615385, 0.0, 0.28846153846153844] [0.7019464148649823, 0.03190436851404899, 0.0, 0.2661492166209687]\n",
      "70000 [0.6712571428571429, 0.006671428571428571, 0.0, 0.32207142857142856] [0.6838295408738566, 0.029671146794881163, 0.0, 0.28649931233126225]\n",
      "75000 [0.64924, 0.00624, 0.0, 0.34452] [0.6697885435583307, 0.027584787020011995, 0.0, 0.3026266694216573]\n",
      "80000 [0.627525, 0.0074, 0.0, 0.365075] [0.625459416502335, 0.031904417566068835, 0.0, 0.3426361659315961]\n",
      "85000 [0.6163411764705883, 0.0074, 0.0, 0.37625882352941176] [0.603188548210725, 0.0322568644877121, 0.0, 0.36455458730156287]\n",
      "90000 [0.5906111111111111, 0.013622222222222223, 0.0, 0.39576666666666666] [0.5671298493702275, 0.03037555026402423, 0.0, 0.4024946003657483]\n"
     ]
    }
   ],
   "source": [
    "print('---------- start requests ----------')\n",
    "acs = []\n",
    "dac = []\n",
    "accesses = [0, 0, 0, 0]\n",
    "dataaccc = [0, 0, 0, 0]\n",
    "count = 0\n",
    "payload = []\n",
    "with requests.Session() as session:\n",
    "    for index, row in all_data.iterrows():\n",
    "        if count > 300000:\n",
    "            break\n",
    "        fs = row['filesize']\n",
    "        payload.append({'filename': index, 'site': row['site'], 'filesize': fs, 'time': row['transfer_start']})\n",
    "        # print(payload)\n",
    "        try:\n",
    "            if count % 100 and count > 0:\n",
    "                r = session.post(service + '/simulate', json=payload)\n",
    "                if r.status_code != 200:\n",
    "                    print(r)\n",
    "                accs = r.json()\n",
    "                for i, j in enumerate(accs['counts']):\n",
    "                    accesses[i] += int(j)\n",
    "                    dataaccc[i] += accs['sizes'][i]\n",
    "                payload = []\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "        if not count % 5000 and count > 0:\n",
    "            # print(count, accesses, dataaccc)\n",
    "            acs.append(accesses.copy())\n",
    "            dac.append(dataaccc.copy())\n",
    "            pacce = []\n",
    "            pdata = []\n",
    "            for i in range(len(accesses)):\n",
    "                pacce.append(accesses[i] / sum(accesses))\n",
    "                pdata.append(dataaccc[i] / sum(dataaccc))\n",
    "            print(count, pacce, pdata)\n",
    "        count += 1\n",
    "\n",
    "print('final: ', accesses, dataaccc)\n",
    "\n",
    "accdf = pd.DataFrame(acs)\n",
    "dacdf = pd.DataFrame(dac)\n",
    "\n",
    "dacdf=dacdf/(1024*1024*1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ploting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accdf.columns = ['level 1', 'level 2', 'level 3', 'origin']\n",
    "dacdf.columns = ['level 1', 'level 2', 'level 3', 'origin']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, constrained_layout=True,figsize=(8,10))\n",
    "\n",
    "# plt.subplot(211)\n",
    "accdf.plot(ax=axs[0])\n",
    "axs[0].set_ylabel('hits')\n",
    "axs[0].set_xlabel('reqeusts [x1000]')\n",
    "axs[0].legend()\n",
    "\n",
    "dacdf.plot(ax=axs[1])\n",
    "axs[1].set_ylabel('data delivered [TB]')\n",
    "axs[1].set_xlabel('reqeusts [x1000]')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('filling_up.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(service + '/status')\n",
    "status = json.loads(res.json())\n",
    "# print(status)\n",
    "tp=[]\n",
    "for site in status:\n",
    "#     print(site[0])\n",
    "#     print(site[1])\n",
    "    tp.append([site[0],site[1]['requests_received'],site[1]['files_delivered'],site[1]['data_delivered']/(1024*1024*1024*1024)])\n",
    "\n",
    "sites=pd.DataFrame(tp)\n",
    "sites.columns=['xcache','requests','hits','data delivered']\n",
    "sites = sites[sites.requests!=0]\n",
    "sites.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True,figsize=(8,8))\n",
    "\n",
    "sites.plot(x=\"xcache\", y=[\"requests\", \"hits\", \"data delivered\"], kind=\"bar\", ax=ax,secondary_y= 'data delivered')\n",
    "fig.savefig('xcache_sites.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
